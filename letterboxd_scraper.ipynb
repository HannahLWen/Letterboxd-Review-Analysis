{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "28108035-cca3-4ec5-a5d6-e4323efd6fd0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import csv\n",
    "import re\n",
    "\n",
    "chrome_options = webdriver.ChromeOptions() \n",
    "chrome_options.add_argument(\"--blink-settings=imagesEnabled=false\") # disabling images to improve run time \n",
    "chrome_options.add_argument('--headless')  # Enable headless mode\n",
    "chrome_options.add_argument('--disable-gpu')  # Disable GPU acceleration in headless mode (optional)\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "\n",
    "\n",
    "fields = [\"Link\", \"Title\", \"Year\", \"Rating\"] # creating data columns\n",
    "filename = \"Letterboxd_scrape_first500.csv\" # new file\n",
    "# creating lists \n",
    "rows = []\n",
    "links = []\n",
    "titles_temp = [] #temporary container for movie info \n",
    "titles = []\n",
    "year = []\n",
    "rating = []\n",
    "errors = []\n",
    "\n",
    "for i in range(1,500):\n",
    "    url = f\"https://letterboxd.com/films/popular/page/{i}/\"\n",
    "    driver.get(url)\n",
    "    try:\n",
    "        #movies = driver.find_elements(By.XPATH, \"//*[@id='films-browser-list-container']/ul/li\") # container of all movies on page\n",
    "        # i put by css selector because it is supposed to be faster\n",
    "        movies = driver.find_elements(By.CSS_SELECTOR, \"#films-browser-list-container ul li\")\n",
    "        for movie in movies: # iterate through movies \n",
    "            movie_info = movie.find_element(By.TAG_NAME, \"a\").get_attribute('data-original-title')\n",
    "            if movie_info.find(\"(\") == -1 or movie_info[-1].isdigit() == False:\n",
    "                continue\n",
    "            titles_temp.append(movie_info) # movie info\n",
    "            links.append(movie.find_element(By.TAG_NAME, \"a\").get_attribute('href')) # link\n",
    "    except: #print page number of where error occurs\n",
    "        errors.append(i)\n",
    "        continue\n",
    "for i in errors:\n",
    "    url = f\"https://letterboxd.com/films/popular/page/{i}/\"\n",
    "    driver.get(url)\n",
    "    try:\n",
    "        #movies = driver.find_elements(By.XPATH, \"//*[@id='films-browser-list-container']/ul/li\") # container of all movies on page\n",
    "        # i put by css selector because it is supposed to be faster\n",
    "        movies = driver.find_elements(By.CSS_SELECTOR, \"#films-browser-list-container ul li\")\n",
    "        for movie in movies: # iterate through movies \n",
    "            \n",
    "            movie_info = movie.find_element(By.TAG_NAME, \"a\").get_attribute('data-original-title')\n",
    "            if movie_info.find(\"(\") == -1 or movie_info[-1].isdigit() == False:\n",
    "                continue\n",
    "            titles_temp.append(movie_info) # movie info\n",
    "            links.append(movie.find_element(By.TAG_NAME, \"a\").get_attribute('href')) # link\n",
    "    except: #print page number of where error occurs\n",
    "        print(\"page: \"+str(i))\n",
    "        continue\n",
    "for film in titles_temp: #iterate through movie info for each one\n",
    "    try:\n",
    "        new_list = re.split(r'[\\(\\)]',film) # split string at parentheses into a new list \n",
    "        new_list = [item.strip() for item in new_list] # strip all parentheses of spaces\n",
    "# append separate features of the movie info \n",
    "        titles.append(new_list[0]) \n",
    "        year.append(new_list[1])\n",
    "        rating.append(new_list[2])\n",
    "    # print movie info when there's an error to track it \n",
    "    except IndexError:\n",
    "        print(new_list)\n",
    "        print(film)\n",
    "        continue\n",
    "for i in range(len(titles)-1): \n",
    "    try:\n",
    "        rows.append([links[i], titles[i], year[i], rating[i]]) # create rows of csv \n",
    "    except IndexError:\n",
    "        print(i) # print index where error occurs \n",
    "with open(filename, 'w') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow(fields) \n",
    "    csvwriter.writerows(rows)\n",
    "\n",
    "driver.quit()\n",
    "print(\"Done\")\n",
    "# done message is because you dont see the webscraping in action in headless mode\n",
    "# 500 pages should take rougly 20ish minutes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8716e9a-9f35-4a83-ab96-c58f5de15194",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
