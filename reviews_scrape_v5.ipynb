{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39bd6e07-c90e-4070-a363-d64fa169adcb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "call me by your name’s cum peach walked so parasite’s killer peach could run\n",
      "Another Bong hit.\n",
      "Our expectations were high but HOLY FUCK\n",
      "a question to people who rate this 4.5: what more do you want literally what more do you want\n",
      "The bloody napkin scene....top 3 scenes of all time. Hands down.\n",
      "morse code me by your name and i'll morse code you by mine\n",
      "The tent won’t leak. It’s from America.\n",
      "Watched with a live orchestra and an introduction by Bong. It was one of my favorite experiences at a theatre, obviously.\n",
      "maybe the real parasite... was the friends we made along the way\n",
      "crazy rich asians walked, so that they could get stabbed in parasite\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait       \n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import csv\n",
    "import re\n",
    "\n",
    "#chrome_options = webdriver.ChromeOptions() \n",
    "#chrome_options.add_argument(\"--blink-settings=imagesEnabled=false\") # disabling images to improve run time \n",
    "#chrome_options.add_argument('--headless')  # Enable headless mode\n",
    "#chrome_options.add_argument('--disable-gpu')  # Disable GPU acceleration in headless mode (optional)\n",
    "#driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "url = \"https://letterboxd.com/film/parasite-2019/reviews/by/activity/page/1/\"\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "source = requests.get(url).text\n",
    "soup = BeautifulSoup(source, 'lxml')\n",
    "divs = soup.find_all(\"div\", class_ = 'body-text -prose collapsible-text') # these contain the reviews\n",
    "\n",
    "count = 0\n",
    "\n",
    "for i in divs: #iterate through reviews of first page,sorted by activit, 12 for each page \n",
    "    count += 1\n",
    "    review = i.p\n",
    "    if review.text == \"This review may contain spoilers. I can handle the truth.\": # skipping reviews with spoilers\n",
    "        # this can easily be found, the paths to it are kinda confusing tho \n",
    "        # you have to go back into the original div without .p and find the hidden tag\n",
    "        review = i.find(\"div\", class_ = \"hidden-spoilers expanded-text\")\n",
    "        \n",
    "    if review.text.find(\"…\") != -1: # skipping reviews that are too long \n",
    "# note: i notice that reviews that are too long have this unique ... thing that you can copy and paste\n",
    "# it detects it easily so we can weed it out but i believe we will have to use selenium for this part \n",
    "# hopefully we will only use selenium for this part as to minimize run time \n",
    "# we should use find by CSS selector for this to minimize time hopefully, \n",
    "# shouldn't be too hard u just have to look up format\n",
    "        #driver.get(url)\n",
    "        #more_button = driver.find_elements(By.XPATH,f\"//*[@id='content']/ul/li[{count}]/p/a\")\n",
    "        #WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH,f\"//*[@id='content']/ul/li[{count}]/p/a\"))).click()\n",
    "        #more_button.click()\n",
    "        #review = driver.find_element(By.CSS_SELECTOR, f\"#content ul li:nth-child({count}) .body-text.-prose.collapsible-text\")\n",
    "        continue\n",
    "    review = review.text.strip()\n",
    "    print(review)\n",
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053939fc-a29b-46d6-89cc-0a63ea8b248c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "282bacb2-42c1-410e-ae27-6c6ec023b15c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“Dad, today I made a plan.”\n",
      "It’s absolutely fucking absurd that Song Kang-Ho did not get any Oscar attention for his role in this film. He gives the most expressive, wide-ranging performance of the year. I mean, the entire ensemble is outstanding (I think I’ve already said how terrific Cho Yeo-jeong’s comedic performance is) but Song is the emotional center of this film both in its funniest and it’s most tragic moments. Also, after five viewings (I know) of this film, it’s so fun to me which line deliveries (in a language I fully do not know) stick out to me so much. Kim Ki-taek screaming “Lady! Are you mad?!” is a strong favorite.\n",
      "I retain a dumb optimism that the Academy will wise up and give this film Best Picture, but even if they don’t, I have no doubt that it simply is the year’s best picture. Every single time I watch this film, I feel my heart breaking at the ending as if it’s the first time.\n"
     ]
    }
   ],
   "source": [
    "# we need to find a way to make this faster\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait       \n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import csv\n",
    "import re\n",
    "import time\n",
    "testurl = 'https://letterboxd.com/film/parasite-2019/reviews/by/activity/page/3/'\n",
    "chrome_options = webdriver.ChromeOptions() \n",
    "chrome_options.add_argument(\"--blink-settings=imagesEnabled=false\") # disabling images to improve run time \n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "driver.get(testurl)\n",
    "testsource = requests.get(testurl).text\n",
    "testsoup = BeautifulSoup(testsource, 'lxml')\n",
    "# this gets the original review with the ... i don't do anything with this im just keeping it in case\n",
    "div = testsoup.find(\"div\", class_ = 'body-text -prose collapsible-text') \n",
    "# getting the more segment from html, very specific to each review\n",
    "\n",
    "\n",
    "driver.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e41eae67-d9c8-4df2-88bd-58394c6eeec9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def more_review(count_li, p_tags):\n",
    "    #p_tags = reviews because reviews catches all the p tags\n",
    "    #using len(p_tags) as the number for which child of the p tag\n",
    "    if len(p_tags) > 1:\n",
    "        more = driver.find_element(By.CSS_SELECTOR, f\"#content > div > div > section > section > ul > li:nth-child({count_li}) > div > div.body-text.-prose.collapsible-text > div > p:nth-child({len(p_tags)}) > a\")\n",
    "        #where the \"more\" button, always at the last paragraph so number would equal len(p_tags)\n",
    "        #count_li corresponds to which of the 12 reviews\n",
    "        more.click()\n",
    "        wait = WebDriverWait(driver, 20)\n",
    "        wait.until(EC.invisibility_of_element_located((By.CSS_SELECTOR,f\"#content > div > div > section > section > ul > li:nth-child({count_li}) > div > div.body-text.-prose.collapsible-text > div > p:nth-child({len(p_tags)}) > a\")))\n",
    "        # most important line of code\n",
    "        time.sleep(1)\n",
    "        # get the review \n",
    "        review = driver.find_element(By.CSS_SELECTOR, f\"#content > div > div > section > section > ul > li:nth-child({count_li}) > div > div.body-text.-prose.collapsible-text\")\n",
    "        #print the review \n",
    "    else:\n",
    "        more = driver.find_element(By.CSS_SELECTOR, f\"#content > div > div > section > section > ul > li:nth-child({count_li}) > div > div.body-text.-prose.collapsible-text > div > p > a\")\n",
    "        more.click()\n",
    "        wait = WebDriverWait(driver, 20)\n",
    "        wait.until(EC.invisibility_of_element_located((By.CSS_SELECTOR,f\"#content > div > div > section > section > ul > li:nth-child({count_li}) > div > div.body-text.-prose.collapsible-text > div > p > a\")))\n",
    "        # most important line of code\n",
    "        time.sleep(1)\n",
    "        review = driver.find_element(By.CSS_SELECTOR, f\"#content > div > div > section > section > ul > li:nth-child({count_li}) > div > div.body-text.-prose.collapsible-text\")\n",
    "        #print the review \n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cd2e7f8-e830-4dc6-816b-2b1b59edcbdd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait       \n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import csv\n",
    "import re\n",
    "import time\n",
    "\n",
    "chrome_options = webdriver.ChromeOptions() \n",
    "chrome_options.add_argument(\"--blink-settings=imagesEnabled=false\") # disabling images to improve run time \n",
    "chrome_options.add_argument('--headless')  # Enable headless mode\n",
    "chrome_options.add_argument('--disable-gpu')  # Disable GPU acceleration in headless mode (optional)\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "filename = \"letterboxd_reviews.csv\"\n",
    "csvfile = open(filename, 'w')\n",
    "csvwriter = csv.writer(csvfile)\n",
    "csvwriter.writerow([\"Parasite reviews\"])\n",
    "#testurl = 'https://letterboxd.com/film/parasite-2019/reviews/by/activity/page/2/'\n",
    "for url_count in range(1, 5):\n",
    "    url = f\"https://letterboxd.com/film/parasite-2019/reviews/by/activity/page/{url_count}/\"\n",
    "\n",
    "    source = requests.get(url).text\n",
    "    soup = BeautifulSoup(source, 'lxml')\n",
    "    divs = soup.find_all(\"div\", class_ = 'body-text -prose collapsible-text') # these contain the reviews\n",
    "    driver.get(url)\n",
    "\n",
    "    count_li = 1\n",
    "\n",
    "\n",
    "\n",
    "    for i in divs: #iterate through reviews of first page,sorted by activit, 12 for each page \n",
    "        reviews = i.find_all(\"p\")\n",
    "        #find all p tags to be able to get over line breaks\n",
    "        if reviews[0].text == \"This review may contain spoilers. I can handle the truth.\": \n",
    "            #reviews[0] because spoilers line is always the only line (paragraph 1)\n",
    "            review = i.find(\"div\", class_ = \"hidden-spoilers expanded-text\").text\n",
    "\n",
    "        elif reviews[-1].text.find(\"… more\") != -1:\n",
    "            #reviews[-1] because \"...\" always last line (last paragraph)\n",
    "            review = more_review(count_li, reviews).text\n",
    "        else:\n",
    "            #if neither spoilers or too long but still paragraph(works for single paragraph too)\n",
    "            review = \"\"\n",
    "            for j in reviews:\n",
    "                review += j.text + \"\\n\"\n",
    "        review = review.strip()\n",
    "\n",
    "        csvwriter.writerow([review])\n",
    "        count_li += 1\n",
    "\n",
    "csvfile.close()\n",
    "driver.close()\n",
    "print(\"Done!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#content > div > div > section > section > ul > li:nth-child(3) > div > div.body-text.-prose.collapsible-text > div > p > a\n",
    "#content > div > div > section > section > ul > li:nth-child(10) > div > div.body-text.-prose.collapsible-text > div > p > a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23f82cb5-f0b3-49b6-ad9c-d06ae8e55dde",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait       \n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import csv\n",
    "import re\n",
    "import time\n",
    "\n",
    "chrome_options = webdriver.ChromeOptions() \n",
    "chrome_options.add_argument(\"--blink-settings=imagesEnabled=false\") # disabling images to improve run time \n",
    "chrome_options.add_argument('--headless')  # Enable headless mode\n",
    "chrome_options.add_argument('--disable-gpu')  # Disable GPU acceleration in headless mode (optional)\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "filename = \"letterboxd_reviews.csv\"\n",
    "csvfile = open(filename, 'w')\n",
    "csvwriter = csv.writer(csvfile)\n",
    "csvwriter.writerow([\"Parasite reviews\"])\n",
    "#testurl = 'https://letterboxd.com/film/parasite-2019/reviews/by/activity/page/2/'\n",
    "\n",
    "url = f\"https://letterboxd.com/film/parasite-2019/reviews/by/activity/page/4/\"\n",
    "\n",
    "source = requests.get(url).text\n",
    "soup = BeautifulSoup(source, 'lxml')\n",
    "divs = soup.find_all(\"div\", class_ = 'body-text -prose collapsible-text') # these contain the reviews\n",
    "driver.get(url)\n",
    "\n",
    "count_li = 1\n",
    "\n",
    "\n",
    "\n",
    "for i in divs: #iterate through reviews of first page,sorted by activit, 12 for each page \n",
    "    reviews = i.find_all(\"p\")\n",
    "    #find all p tags to be able to get over line breaks\n",
    "    if reviews[0].text == \"This review may contain spoilers. I can handle the truth.\": \n",
    "        #reviews[0] because spoilers line is always the only line (paragraph 1)\n",
    "        review = i.find(\"div\", class_ = \"hidden-spoilers expanded-text\").text\n",
    "\n",
    "    elif reviews[-1].text.find(\"… more\") != -1:\n",
    "        #reviews[-1] because \"...\" always last line (last paragraph)\n",
    "        review = more_review(count_li, reviews).text\n",
    "    else:\n",
    "        #if neither spoilers or too long but still paragraph(works for single paragraph too)\n",
    "        review = \"\"\n",
    "        for j in reviews:\n",
    "            review += j.text + \"\\n\"\n",
    "    review = review.strip()\n",
    "\n",
    "    csvwriter.writerow([review])\n",
    "    count_li += 1\n",
    "\n",
    "csvfile.close()\n",
    "driver.close()\n",
    "print(\"Done!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#content > div > div > section > section > ul > li:nth-child(3) > div > div.body-text.-prose.collapsible-text > div > p > a\n",
    "#content > div > div > section > section > ul > li:nth-child(10) > div > div.body-text.-prose.collapsible-text > div > p > a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5505a64d-8d75-47a0-a88b-e934eb94225d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait       \n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import csv\n",
    "import re\n",
    "import time\n",
    "from pandas import *\n",
    "\n",
    "chrome_options = webdriver.ChromeOptions() \n",
    "chrome_options.add_argument(\"--blink-settings=imagesEnabled=false\") # disabling images to improve run time \n",
    "chrome_options.add_argument('--headless')  # Enable headless mode\n",
    "chrome_options.add_argument('--disable-gpu')  # Disable GPU acceleration in headless mode (optional)\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "#opens file for reviews\n",
    "filename_reviews = \"letterboxd_reviews_v2.csv\"\n",
    "csvfile_reviews = open(filename_reviews, 'w')\n",
    "csvwriter_reviews = csv.writer(csvfile_reviews)\n",
    "#open info to read\n",
    "data_info = read_csv(\"Letterboxd_scrape_first500.csv\")\n",
    "links = data_info['Link'].tolist()\n",
    "titles = data_info['Title'].tolist()\n",
    "\n",
    "\n",
    "\n",
    "for index,link in enumerate(links):\n",
    "    if index == 5:\n",
    "        break\n",
    "    all_reviews = []\n",
    "    for url_count in range(1, 5):\n",
    "        url = f\"{link}reviews/by/activity/page/{url_count}/\"\n",
    "\n",
    "        source = requests.get(url).text\n",
    "        soup = BeautifulSoup(source, 'lxml')\n",
    "        divs = soup.find_all(\"div\", class_ = 'body-text -prose collapsible-text') # these contain the reviews\n",
    "        driver.get(url)\n",
    "\n",
    "        count_li = 1\n",
    "\n",
    "\n",
    "\n",
    "        for i in divs: #iterate through reviews of first page,sorted by activit, 12 for each page \n",
    "            reviews = i.find_all(\"p\")\n",
    "            #find all p tags to be able to get over line breaks\n",
    "            if reviews[0].text == \"This review may contain spoilers. I can handle the truth.\": \n",
    "                #reviews[0] because spoilers line is always the only line (paragraph 1)\n",
    "                review = i.find(\"div\", class_ = \"hidden-spoilers expanded-text\").text\n",
    "\n",
    "            elif reviews[-1].text.find(\"… more\") != -1:\n",
    "                #reviews[-1] because \"...\" always last line (last paragraph)\n",
    "                review = more_review(count_li, reviews).text\n",
    "            else:\n",
    "                #if neither spoilers or too long but still paragraph(works for single paragraph too)\n",
    "                review = \"\"\n",
    "                for j in reviews:\n",
    "                    review += j.text + \"\\n\"\n",
    "            review = review.strip()\n",
    "\n",
    "            all_reviews.append(review)\n",
    "            \n",
    "            count_li += 1\n",
    "    csvwriter_reviews.writerow([titles[index],all_reviews])\n",
    "csvfile_reviews.close()\n",
    "driver.close()\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "916713ae-911b-4a7e-8b15-6c0092f68156",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait       \n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import csv\n",
    "import re\n",
    "import time\n",
    "from pandas import *\n",
    "\n",
    "chrome_options = webdriver.ChromeOptions() \n",
    "chrome_options.add_argument(\"--blink-settings=imagesEnabled=false\") # disabling images to improve run time \n",
    "chrome_options.add_argument('--headless')  # Enable headless mode\n",
    "chrome_options.add_argument('--disable-gpu')  # Disable GPU acceleration in headless mode (optional)\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "#opens file for reviews\n",
    "filename_reviews = \"letterboxd_reviews_v2.csv\"\n",
    "csvfile_reviews = open(filename_reviews, 'w')\n",
    "csvwriter_reviews = csv.writer(csvfile_reviews)\n",
    "#open info to read\n",
    "data_info = read_csv(\"Letterboxd_scrape_first500.csv\")\n",
    "links = data_info['Link'].tolist()\n",
    "titles = data_info['Title'].tolist()\n",
    "\n",
    "for i in titles:\n",
    "    csvwriter_reviews.writerow([i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6e3e2a-9fc5-474f-80f8-f823afe570e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
