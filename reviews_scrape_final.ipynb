{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7dce940-37a9-4e92-b64a-599385da21b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait       \n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import csv\n",
    "import re\n",
    "import time\n",
    "import pandas as pd \n",
    "import pymysql"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e771a9c-4e4a-4c7e-b643-903806487cb7",
   "metadata": {},
   "source": [
    "# Preparing Information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8620291e-0c62-4e65-8a2a-0b22d836b41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turning the data collected on movies into separate lists \n",
    "titles_df = pd.read_csv('Letterboxd_scrape_first500_final.csv')\n",
    "links = titles_df['Link'].tolist()\n",
    "titles = titles_df['Title'].tolist()\n",
    "years = list(map(int, titles_df['Year'].tolist()))\n",
    "ratings = titles_df['Rating'].tolist()\n",
    "synopses = titles_df['Synopsis'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9072503c-6b83-4b83-9c1e-408faceb4b38",
   "metadata": {},
   "source": [
    "# Webscraping Reviews \n",
    "### An example line of code to run this: \n",
    "### parsing_through(titles, years, links, ratings, synopses, 1987, 2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49a5ac3d-b917-4552-92a4-1ae2d8e184e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# give lists of all information from csv, plus limit of movies \n",
    "# function parses through the list of titles to collect ratings by calling other functions\n",
    "# collects reviews according to the indexes given which correlate to the indexes of the movies in the list\n",
    "def parsing_through(titles, years, links, ratings, synopses, start, end):\n",
    "    db = pymysql.connect(host='localhost', user = 'hester',\n",
    "                             passwd = '****', database = \"letterboxd_project\")\n",
    "    cursor = db.cursor()\n",
    "    # for each movie \n",
    "    for i in range(start,end):\n",
    "        # getting movie specific information \n",
    "        title, year, link, rating, synopsis = titles[i], years[i], links[i], ratings[i], synopses[i]\n",
    "        review_list = collect_reviews(link) # list of reviews from collect function\n",
    "        # creating list of rows \n",
    "        rows_to_insert = []\n",
    "        # for each review collected, create new row\n",
    "        for review in review_list:\n",
    "            # first_100 is an identifier for the first 100 characters to define uniqueness\n",
    "            try:\n",
    "                first_100 = review[0:99]\n",
    "            except:\n",
    "                first_100 = review\n",
    "            new_row = (title, year, synopsis,review, first_100)\n",
    "            rows_to_insert.append(new_row)\n",
    "        # insert rows into sql data base \n",
    "        insert_query = \"INSERT IGNORE INTO movie_reviews (movie_title, release_year, synopsis, review, first_100) VALUES (%s, %s, %s, %s, %s)\"\n",
    "        cursor.executemany(insert_query, rows_to_insert)\n",
    "        db.commit()\n",
    "    cursor.close()\n",
    "    db.close()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e41eae67-d9c8-4df2-88bd-58394c6eeec9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# function to reveal the more button when a review is long \n",
    "def more_review(count_li, p_tags):\n",
    "    #p_tags = reviews because reviews catches all the p tags\n",
    "    #using len(p_tags) as the number for which child of the p tag\n",
    "    chrome_options = webdriver.ChromeOptions() \n",
    "    chrome_options.add_argument(\"--blink-settings=imagesEnabled=false\") # disabling images to improve run time \n",
    "    chrome_options.add_argument('--headless')  # Enable headless mode\n",
    "    chrome_options.add_argument('--no-sandbox')\n",
    "    #chrome_options.add_argument('--disable-gpu')  # Disable GPU acceleration in headless mode (optional)\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    if len(p_tags) > 1:\n",
    "        more = driver.find_element(By.CSS_SELECTOR, f\"#content > div > div > section > section > ul > li:nth-child({count_li}) > div > div.body-text.-prose.collapsible-text > div > p:nth-child({len(p_tags)}) > a\")\n",
    "        #where the \"more\" button, always at the last paragraph so number would equal len(p_tags)\n",
    "        #count_li corresponds to which of the 12 reviews\n",
    "        more.click()\n",
    "        wait = WebDriverWait(driver, 20)\n",
    "        wait.until(EC.invisibility_of_element_located((By.CSS_SELECTOR,f\"#content > div > div > section > section > ul > li:nth-child({count_li}) > div > div.body-text.-prose.collapsible-text > div > p:nth-child({len(p_tags)}) > a\")))\n",
    "        time.sleep(1)\n",
    "        # get the review \n",
    "        review = driver.find_element(By.CSS_SELECTOR, f\"#content > div > div > section > section > ul > li:nth-child({count_li}) > div > div.body-text.-prose.collapsible-text\")\n",
    "    else:\n",
    "        more = driver.find_element(By.CSS_SELECTOR, f\"#content > div > div > section > section > ul > li:nth-child({count_li}) > div > div.body-text.-prose.collapsible-text > div > p > a\")\n",
    "        more.click()\n",
    "        wait = WebDriverWait(driver, 20)\n",
    "        wait.until(EC.invisibility_of_element_located((By.CSS_SELECTOR,f\"#content > div > div > section > section > ul > li:nth-child({count_li}) > div > div.body-text.-prose.collapsible-text > div > p > a\")))\n",
    "        time.sleep(1)\n",
    "        review = driver.find_element(By.CSS_SELECTOR, f\"#content > div > div > section > section > ul > li:nth-child({count_li}) > div > div.body-text.-prose.collapsible-text\")\n",
    "    driver.close()\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25e737a3-9a1b-4510-9715-0fd90d0d56bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collects reviews from each page\n",
    "def collect_reviews(link):\n",
    "    chrome_options = webdriver.ChromeOptions() \n",
    "    chrome_options.add_argument(\"--blink-settings=imagesEnabled=false\") # disabling images to improve run time \n",
    "    chrome_options.add_argument('--headless')  # Enable headless mode\n",
    "    chrome_options.add_argument('--no-sandbox')\n",
    "    #chrome_options.add_argument('--disable-gpu')  # Disable GPU acceleration in headless mode (optional)\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    movie_reviews = [] # creating list of movie reviews \n",
    "    for url_count in range(1, 5): # iterate through each review page\n",
    "        url = f\"{link}reviews/by/activity/page/{url_count}/\"\n",
    "        source = requests.get(url).text\n",
    "        soup = BeautifulSoup(source, 'lxml')\n",
    "        divs = soup.find_all(\"div\", class_ = 'body-text -prose collapsible-text') # these contain the reviews\n",
    "        driver.get(url)\n",
    "        count_li = 1\n",
    "        for i in divs: #iterate through reviews of first page,sorted by activit, 12 for each page \n",
    "            reviews = i.find_all(\"p\")\n",
    "            #find all p tags to be able to get over line breaks\n",
    "            if reviews[0].text == \"This review may contain spoilers. I can handle the truth.\": \n",
    "                #reviews[0] because spoilers line is always the only line (paragraph 1)\n",
    "                review = i.find(\"div\", class_ = \"hidden-spoilers expanded-text\").text\n",
    "\n",
    "            elif reviews[-1].text.find(\"â€¦ more\") != -1:\n",
    "                #reviews[-1] because \"...\" always last line (last paragraph)\n",
    "                review = more_review(count_li, reviews).text\n",
    "            else:\n",
    "                #if neither spoilers or too long but still paragraph(works for single paragraph too)\n",
    "                review = \"\"\n",
    "                for j in reviews:\n",
    "                    review += j.text + \"\\n\"\n",
    "            review = review.strip()\n",
    "            # movies are appending in one big list \n",
    "            movie_reviews.append(review)\n",
    "            count_li += 1\n",
    "    driver.close()\n",
    "    return(movie_reviews)\n",
    "\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
